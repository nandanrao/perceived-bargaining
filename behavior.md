# Applications Data

Many people use Employment Opportunity Pilot Project -- 1980-1982. This is naturally useless to me. How can I get some data that shows an increase in job applications???

# Introduction

The hypothesis of this paper is nothing more than "the more rejections you get when applying for a certain type of job, the lower you percieve your chances to be of actually getting such a job." In and of itself, this is not very controversial and, Ceteris Paribus, this is exactly what any model of rationality would predict. The hypothesis here, however, is specifically that even Ceteris very-much-not-paribus, and even when one's chances of geting a job are not actually lower, one might percieve them to be this way and act accordingly.

I hope it is uncontroversial to claim that applying for jobs is, in the minds of those who do it, and in the best way we can model it, a probabalistic event. Applying to jobs is arguably an evolutionary game: there are too many other players (all other job applicants and all other firms) to begin to claim that agents rationalize even a single level of reasoning in a traditional game-theoretic framework. Agents are therefore forced to follow myopic strategies, and these myopic strategies, I will assume, inherently involve estimating the probability of getting each job before bothering to send in an application.

The context of this paper will be to consider potential effects of a technology change that reduces the cost of applying to each job. Recent history is rife with such technologies, from the fax machine to the internet, to integrated profile-cum-job-boards such as LinkedIn. It is not hard to imagine that yet more such technological changes await us in the near future.

Given a reduction of costs, be they time or money, the number of applications sent per job-seekershould, theoretically, increase as the per-application cost decreases. Assuming that interviewing is still a process that requires human time, as it will to some degree always, it is clear to see that the number of outright rejections the average job-seeker receives must naturally go up with the number of applications the average job-seeker sends.

It is worth noting the difference in implication between technologies that lower search costs and those that lower application costs, especially as both are associated with similar technologies in real life. Lowering search costs in and of themselves would imply not more applications, but better-targeted applications. Independently of the potential implications of better-targeted applications, however, if the cost of applying goes down and therefore the number of applications sent goes up, then it must necessarily lead to more rejections, regardless of how well those applications are targeted to begin with.

For concretness, consider an applicant that has just spent a day applying to jobs and not receieved a single interview. Should the applicant spend another day applying to yet more jobs of the same kind, or should they direct their search to jobs that they deem "easier to get", jobs that by revealed preference must naturally be less desireable? This is clearly a question of expected utility and, given the fixed opportunity cost of one day and the known utility of recieving one of these jobs, the only piece of information that the applicant must attempt to estimate is the probability of acceptance.

What can go wrong, then, when people attempt to estimate the probability of getting a job? This is learning by experience: our applicant has had an experience of applying and being rejected and must learn the probability of further rejection. If acceptance is a "rare event", then we can expect applicants to underestimate its probability (cite: ).
